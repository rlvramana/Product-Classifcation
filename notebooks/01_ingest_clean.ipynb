{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae306ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import ok; project_root = /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation\n"
     ]
    }
   ],
   "source": [
    "# Make 'src' importable and define absolute-style project paths.\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Find the project root by walking up until we see both 'src' and 'data'\n",
    "candidates = [Path.cwd(), *Path.cwd().parents]\n",
    "project_root = next((p for p in candidates if (p / \"src\").exists() and (p / \"data\").exists()), None)\n",
    "if project_root is None:\n",
    "    raise RuntimeError(f\"Could not find project root from {Path.cwd()}\")\n",
    "\n",
    "# Add the ROOT (not 'src') to sys.path so \"from src...\" works\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.cleaning_utils import normalize_text\n",
    "print(\"import ok; project_root =\", project_root)\n",
    "\n",
    "# Define key folders once, reuse everywhere\n",
    "DATA = project_root / \"data\"\n",
    "RAW = DATA / \"raw\"          #  monthly folders live here\n",
    "INTERIM = DATA / \"interim\"  # intermediate outputs go here\n",
    "INTERIM.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36acfd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample files found: 3 under /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation/data/raw\n",
      "rows: 26322 saved to /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation/data/interim/events_sample.parquet\n"
     ]
    }
   ],
   "source": [
    "# Read a few JSON files, clean product names, and write a small Parquet sample.\n",
    "\n",
    "import polars as pl  # fast DataFrame library (tables)   \n",
    "\n",
    "files = list(RAW.rglob(\"*.json\"))[:3]\n",
    "print(\"sample files found:\", len(files), \"under\", RAW)\n",
    "\n",
    "dfs = []\n",
    "for fp in files:\n",
    "    try:\n",
    "        # NDJSON = one JSON object per line; read it efficiently\n",
    "        df = (\n",
    "            pl.read_ndjson(str(fp), infer_schema_length=1000)  # reads NDJSON  \n",
    "              .select(pl.col(\"remove_amazon\").cast(pl.Utf8).alias(\"raw_text\"))\n",
    "        )\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(\"skip\", fp, \"->\", e)\n",
    "\n",
    "if dfs:\n",
    "    out = (\n",
    "        pl.concat(dfs, how=\"vertical\")\n",
    "          .with_columns(pl.col(\"raw_text\").map_elements(normalize_text).alias(\"product_text\"))\n",
    "          .select(\"product_text\")\n",
    "          .filter(pl.col(\"product_text\").str.len_bytes() > 0)\n",
    "          .unique()\n",
    "    )\n",
    "    out_path = INTERIM / \"events_sample.parquet\"\n",
    "    out.write_parquet(out_path)  # fast, columnar format   \n",
    "    print(\"rows:\", out.height, \"saved to\", out_path)\n",
    "else:\n",
    "    print(\"no JSON files found — check that your monthly .json files are inside\", RAW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ab9c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation/data/labels/google_fashion_retailer_cleaning_final - FOR MSU.xlsm\n",
      "unique product names in selected months: 124167\n",
      "matched 1698 / 124167 (1.37%)\n",
      "class counts:\n",
      " shape: (2, 2)\n",
      "┌───────┬──────┐\n",
      "│ label ┆ len  │\n",
      "│ ---   ┆ ---  │\n",
      "│ i8    ┆ u32  │\n",
      "╞═══════╪══════╡\n",
      "│ 0     ┆ 314  │\n",
      "│ 1     ┆ 1384 │\n",
      "└───────┴──────┘\n",
      "wrote: /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation/data/interim/events_AUG-24.parquet\n",
      "wrote: /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation/data/interim/labeled_AUG-24.parquet\n"
     ]
    }
   ],
   "source": [
    "# PURPOSE: build a month-sized labeled dataset from raw JSON, for any months you choose.\n",
    "# We classify product names ONLY (search terms are ignored).\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from src.cleaning_utils import normalize_text\n",
    "\n",
    "# ---------- configure months here ----------\n",
    "# Folder names must match your data/raw structure, e.g. \"export_shopper=AUG-24\"\n",
    "MONTHS = [\"export_shopper=AUG-24\"]   # add more: [\"export_shopper=AUG-24\",\"export_shopper=SEP-24\"]\n",
    "DEDUP_EVENTS = True                  # keep unique product names to reduce size\n",
    "# ------------------------------------------\n",
    "\n",
    "# Locate project folders\n",
    "project_root = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p / \"data\").exists()), Path.cwd())\n",
    "DATA = project_root / \"data\"\n",
    "RAW = DATA / \"raw\"\n",
    "INTERIM = DATA / \"interim\"\n",
    "LABELS_XLSX = next((DATA / \"labels\").glob(\"*.xls*\"))\n",
    "\n",
    "print(\"labels:\", LABELS_XLSX)\n",
    "\n",
    "# A) read labels (product_name + relevant_code) and normalize -> product_text\n",
    "labels_df = pd.read_excel(LABELS_XLSX, engine=\"openpyxl\")\n",
    "cols = {c.lower().strip(): c for c in labels_df.columns}\n",
    "assert \"product_name\" in cols, \"Expected 'product_name' in labels\"\n",
    "if \"relevant_code\" in cols:\n",
    "    labels_df[\"label\"] = (labels_df[cols[\"relevant_code\"]] == 1).astype(\"int8\")\n",
    "elif \"label\" not in cols:\n",
    "    raise AssertionError(\"Need 'relevant_code' or 'label' in labels\")\n",
    "labels_df[\"product_text\"] = labels_df[cols[\"product_name\"]].astype(str).map(normalize_text)\n",
    "labels_pl = pl.from_pandas(labels_df[[\"product_text\", \"label\"]]).unique()\n",
    "\n",
    "# B) read ALL NDJSON files for the selected months and normalize -> product_text\n",
    "def read_month(folder_name: str) -> pl.DataFrame:\n",
    "    month_dir = RAW / folder_name\n",
    "    files = sorted(month_dir.rglob(\"*.json\"))\n",
    "    if not files:\n",
    "        print(\"no files in\", month_dir)\n",
    "        return pl.DataFrame({\"product_text\": pl.Series([], dtype=pl.Utf8)})\n",
    "    dfs = []\n",
    "    for fp in files:\n",
    "        try:\n",
    "            df = (\n",
    "                pl.read_ndjson(str(fp), infer_schema_length=1000)\n",
    "                  .select(pl.col(\"remove_amazon\").cast(pl.Utf8).alias(\"raw_text\"))\n",
    "            )\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(\"skip\", fp, \"->\", e)\n",
    "    ev = pl.concat(dfs, how=\"vertical\").with_columns(\n",
    "        pl.col(\"raw_text\").map_elements(normalize_text).alias(\"product_text\")\n",
    "    ).select(\"product_text\")\n",
    "    return ev.unique() if DEDUP_EVENTS else ev\n",
    "\n",
    "all_events = [read_month(m) for m in MONTHS]\n",
    "events = pl.concat([e for e in all_events if e.height > 0], how=\"vertical\")\n",
    "print(\"unique product names in selected months:\", events.height)\n",
    "\n",
    "# C) exact join by cleaned text\n",
    "joined = events.join(labels_pl, on=\"product_text\", how=\"left\")\n",
    "matched = joined.filter(pl.col(\"label\").is_not_null())\n",
    "\n",
    "# D) coverage and class counts\n",
    "total = events.height\n",
    "matched_n = matched.height\n",
    "coverage = matched_n / max(total, 1)\n",
    "print(f\"matched {matched_n} / {total} ({coverage:.2%})\")\n",
    "print(\"class counts:\\n\", matched.group_by(\"label\").len().sort(\"label\"))\n",
    "\n",
    "# E) save month outputs\n",
    "tag = \"-\".join([m.split(\"=\")[-1] for m in MONTHS])  # e.g., \"AUG-24\" or \"AUG-24-SEP-24\"\n",
    "events_out = INTERIM / f\"events_{tag}.parquet\"\n",
    "labeled_out = INTERIM / f\"labeled_{tag}.parquet\"\n",
    "events.write_parquet(events_out)\n",
    "matched.write_parquet(labeled_out)\n",
    "print(\"wrote:\", events_out)\n",
    "print(\"wrote:\", labeled_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c3cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique product names (events): 124167\n",
      "labeled matches: 1698 coverage: 1.37%\n",
      "\n",
      "class counts and ratio:\n",
      "shape: (2, 3)\n",
      "┌───────┬──────┬──────────┐\n",
      "│ label ┆ len  ┆ pct      │\n",
      "│ ---   ┆ ---  ┆ ---      │\n",
      "│ i8    ┆ u32  ┆ f64      │\n",
      "╞═══════╪══════╪══════════╡\n",
      "│ 0     ┆ 314  ┆ 0.184923 │\n",
      "│ 1     ┆ 1384 ┆ 0.815077 │\n",
      "└───────┴──────┴──────────┘\n",
      "\n",
      "length stats (chars) on product_text:\n",
      "shape: (9, 2)\n",
      "┌────────────┬────────────┐\n",
      "│ statistic  ┆ txt_len    │\n",
      "│ ---        ┆ ---        │\n",
      "│ str        ┆ f64        │\n",
      "╞════════════╪════════════╡\n",
      "│ count      ┆ 1698.0     │\n",
      "│ null_count ┆ 0.0        │\n",
      "│ mean       ┆ 108.156655 │\n",
      "│ std        ┆ 40.973584  │\n",
      "│ min        ┆ 0.0        │\n",
      "│ 25%        ┆ 80.0       │\n",
      "│ 50%        ┆ 105.0      │\n",
      "│ 75%        ┆ 132.0      │\n",
      "│ max        ┆ 211.0      │\n",
      "└────────────┴────────────┘\n",
      "\n",
      "sample positives:\n",
      "shape: (5, 1)\n",
      "┌─────────────────────────────────┐\n",
      "│ product_text                    │\n",
      "│ ---                             │\n",
      "│ str                             │\n",
      "╞═════════════════════════════════╡\n",
      "│ niftriry women hippie tassel p… │\n",
      "│ ablanczoom womens sandals flat… │\n",
      "│ angel fashions women s sequin … │\n",
      "│ disney princess disney moana n… │\n",
      "│ nike womens superrep go 3 flyk… │\n",
      "└─────────────────────────────────┘\n",
      "\n",
      "sample negatives:\n",
      "shape: (5, 1)\n",
      "┌─────────────────────────────────┐\n",
      "│ product_text                    │\n",
      "│ ---                             │\n",
      "│ str                             │\n",
      "╞═════════════════════════════════╡\n",
      "│ oropy industrial pipe clothing… │\n",
      "│ sorbus makeup organizer with 2… │\n",
      "│ sersper memory foam hybrid pil… │\n",
      "│ goody king resin jewelry makin… │\n",
      "│ beautural fabric shaver and li… │\n",
      "└─────────────────────────────────┘\n",
      "\n",
      "common tokens in positives:\n",
      "shape: (20, 2)\n",
      "┌───────┬─────┐\n",
      "│ toks  ┆ len │\n",
      "│ ---   ┆ --- │\n",
      "│ str   ┆ u32 │\n",
      "╞═══════╪═════╡\n",
      "│ women ┆ 793 │\n",
      "│ for   ┆ 688 │\n",
      "│ s     ┆ 555 │\n",
      "│ with  ┆ 279 │\n",
      "│ men   ┆ 242 │\n",
      "│ …     ┆ …   │\n",
      "│ tops  ┆ 126 │\n",
      "│ dress ┆ 122 │\n",
      "│ t     ┆ 121 │\n",
      "│ black ┆ 118 │\n",
      "│ shirt ┆ 113 │\n",
      "└───────┴─────┘\n",
      "\n",
      "common tokens in negatives:\n",
      "shape: (20, 2)\n",
      "┌─────────┬─────┐\n",
      "│ toks    ┆ len │\n",
      "│ ---     ┆ --- │\n",
      "│ str     ┆ u32 │\n",
      "╞═════════╪═════╡\n",
      "│ for     ┆ 284 │\n",
      "│ with    ┆ 162 │\n",
      "│ and     ┆ 124 │\n",
      "│ jewelry ┆ 115 │\n",
      "│ resin   ┆ 73  │\n",
      "│ …       ┆ …   │\n",
      "│ rack    ┆ 37  │\n",
      "│ pliers  ┆ 36  │\n",
      "│ jump    ┆ 36  │\n",
      "│ case    ┆ 35  │\n",
      "│ laundry ┆ 35  │\n",
      "└─────────┴─────┘\n"
     ]
    }
   ],
   "source": [
    "# PURPOSE: EDA-lite on labeled_AUG-24.parquet (product names only)\n",
    "\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "\n",
    "# locate files\n",
    "project_root = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p / \"data\").exists()), Path.cwd())\n",
    "DATA = project_root / \"data\"\n",
    "LAB = DATA / \"interim\" / \"labeled_AUG-24.parquet\"\n",
    "EVT = DATA / \"interim\" / \"events_AUG-24.parquet\"\n",
    "\n",
    "lab = pl.read_parquet(LAB)\n",
    "ev  = pl.read_parquet(EVT)\n",
    "\n",
    "print(\"unique product names (events):\", ev.height)\n",
    "print(\"labeled matches:\", lab.height, f\"coverage: {lab.height/ev.height:.2%}\")\n",
    "\n",
    "print(\"\\nclass counts and ratio:\")\n",
    "print(\n",
    "    lab.group_by(\"label\").len()\n",
    "       .with_columns((pl.col(\"len\")/lab.height).alias(\"pct\"))\n",
    "       .sort(\"label\")\n",
    ")\n",
    "\n",
    "print(\"\\nlength stats (chars) on product_text:\")\n",
    "print(\n",
    "    lab.with_columns(pl.col(\"product_text\").str.len_chars().alias(\"txt_len\"))\n",
    "       .select(\"txt_len\")\n",
    "       .describe()\n",
    ")\n",
    "\n",
    "print(\"\\nsample positives:\")\n",
    "print(lab.filter(pl.col(\"label\")==1).select(\"product_text\").head(5))\n",
    "\n",
    "print(\"\\nsample negatives:\")\n",
    "print(lab.filter(pl.col(\"label\")==0).select(\"product_text\").head(5))\n",
    "\n",
    "def top_tokens(df, k=20):\n",
    "    toks = (df.with_columns(pl.col(\"product_text\").str.split(\" \").alias(\"toks\"))\n",
    "              .explode(\"toks\")\n",
    "              .filter(pl.col(\"toks\")!=\"\")\n",
    "              .group_by(\"toks\").len()\n",
    "              .sort(\"len\", descending=True)\n",
    "              .head(k))\n",
    "    return toks\n",
    "\n",
    "print(\"\\ncommon tokens in positives:\")\n",
    "print(top_tokens(lab.filter(pl.col(\"label\")==1)))\n",
    "\n",
    "print(\"\\ncommon tokens in negatives:\")\n",
    "print(top_tokens(lab.filter(pl.col(\"label\")==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a32cd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9608\n",
      "Validation macro F1: 0.9337\n",
      "\n",
      "Test accuracy: 0.9255\n",
      "Test macro F1: 0.8771\n",
      "Test PR-AUC (avg precision): 0.9964\n",
      "\n",
      "Classification report (test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.792     0.809     0.800        47\n",
      "           1      0.957     0.952     0.954       208\n",
      "\n",
      "    accuracy                          0.925       255\n",
      "   macro avg      0.874     0.880     0.877       255\n",
      "weighted avg      0.926     0.925     0.926       255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PURPOSE: Train a leakage-safe baseline on AUG-24 labeled data\n",
    "# Concepts:\n",
    "# - TF-IDF: turns words/word-pairs into numeric features (importance-weighted)  [scikit-learn docs]\n",
    "# - Logistic Regression: fast linear classifier well-suited to sparse text       [scikit-learn docs]\n",
    "# - Stratified split: keeps class ratio in train/val/test                         [scikit-learn docs]\n",
    "# - Metrics for imbalance: accuracy + macro-F1 + PR-AUC (average precision)      \n",
    "\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split                      # stratify  [docs]\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer               # TF-IDF    [docs]\n",
    "from sklearn.linear_model import LogisticRegression                       # LR        [docs]\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, average_precision_score\n",
    "\n",
    "# 1) Load labeled month\n",
    "project_root = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p / \"data\").exists()), Path.cwd())\n",
    "LAB = project_root / \"data\" / \"interim\" / \"labeled_AUG-24.parquet\"\n",
    "df = pl.read_parquet(LAB).select(\"product_text\", \"label\").unique()  # defensive dedupe\n",
    "pdf = df.to_pandas()\n",
    "\n",
    "X = pdf[\"product_text\"].astype(str).values\n",
    "y = pdf[\"label\"].astype(int).values\n",
    "\n",
    "# 2) Stratified 70/15/15 split (train/val/test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# 3) Vectorize text (unigrams+bigrams); min_df=2 to ignore ultra-rare tokens\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2), min_df=2)\n",
    "Xtr = tfidf.fit_transform(X_train)\n",
    "Xv  = tfidf.transform(X_val)\n",
    "Xt  = tfidf.transform(X_test)\n",
    "\n",
    "# 4) Train classifier; class_weight='balanced' helps on imbalance\n",
    "clf = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "clf.fit(Xtr, y_train)\n",
    "\n",
    "# 5) Evaluate with both labels and probabilities (for PR-AUC)\n",
    "pred_val = clf.predict(Xv)\n",
    "pred_test = clf.predict(Xt)\n",
    "proba_test = clf.predict_proba(Xt)[:, 1]\n",
    "\n",
    "print(\"Validation accuracy:\", round(accuracy_score(y_val, pred_val), 4))\n",
    "print(\"Validation macro F1:\", round(f1_score(y_val, pred_val, average='macro'), 4))\n",
    "\n",
    "print(\"\\nTest accuracy:\", round(accuracy_score(y_test, pred_test), 4))\n",
    "print(\"Test macro F1:\", round(f1_score(y_test, pred_test, average='macro'), 4))\n",
    "print(\"Test PR-AUC (avg precision):\", round(average_precision_score(y_test, proba_test), 4))\n",
    "\n",
    "print(\"\\nClassification report (test):\\n\", classification_report(y_test, pred_test, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b828039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default threshold (0.5) — validation:\n",
      "  acc: 0.9412 macro F1: 0.906\n",
      "  confusion matrix:\n",
      " [[ 42   5]\n",
      " [ 10 198]]\n",
      "\n",
      "Default threshold (0.5) — test:\n",
      "  acc: 0.949 macro F1: 0.9185\n",
      "  confusion matrix:\n",
      " [[ 43   4]\n",
      " [  9 199]]\n",
      "\n",
      "Best threshold by validation accuracy: 0.525 -> acc: 0.9451 macro F1: 0.9142\n",
      "Best threshold by validation macro-F1: 0.525 -> acc: 0.9451 macro F1: 0.9142\n",
      "\n",
      "Tuned-by-accuracy — test:\n",
      "  thr: 0.525 acc: 0.949 macro F1: 0.9198\n",
      "  confusion matrix:\n",
      " [[ 44   3]\n",
      " [ 10 198]]\n",
      "\n",
      "Tuned-by-macro-F1 — test:\n",
      "  thr: 0.525 acc: 0.949 macro F1: 0.9198\n",
      "  confusion matrix:\n",
      " [[ 44   3]\n",
      " [ 10 198]]\n",
      "\n",
      "Top 5 false positives (pred=1 but y=0):\n",
      "   score                                                                             text\n",
      "0.683180 charmma women s plus size halloween dress pumpkin costume flared dresses vint...\n",
      "0.564281 drnaiety 2 pairs compression gloves for hand arthritis rheumatoid osteoarthri...\n",
      "0.558027 sersper memory foam hybrid pillow top queen mattress 5 zone pocket innersprin...\n",
      "\n",
      "Top 5 false negatives (pred=0 but y=1):\n",
      "   score                                                                             text\n",
      "0.293444 spooktacular creations pink 80s costume set with t shirt tutu headband others...\n",
      "0.318500 lot 110 pcs body jewelry piercing kit eyebrow navel belly tongue lip bar nose...\n",
      "0.375298 sleeping lamb stackable hat organzier for baseball caps 2 pcs hat storage box...\n",
      "0.407601 counter culture diy nice n thick epoxy resin thickener increase viscosity pow...\n",
      "0.413120 goku earring and ring one pair of anime black goku cosplay accessories earrin...\n",
      "\n",
      "Test PR-AUC (avg precision): 0.9972\n"
     ]
    }
   ],
   "source": [
    "# PURPOSE: error analysis + threshold tuning for the AUG-24 baseline (product names only)\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split                  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer           \n",
    "from sklearn.linear_model import LogisticRegression                 \n",
    "from sklearn.metrics import (accuracy_score, f1_score, average_precision_score,\n",
    "                             precision_recall_curve, confusion_matrix, classification_report) \n",
    "\n",
    "# 1) Load labeled month and split\n",
    "root = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p / \"data\").exists()), Path.cwd())\n",
    "lab_path = root / \"data\" / \"interim\" / \"labeled_AUG-24.parquet\"\n",
    "df = pl.read_parquet(lab_path).select(\"product_text\", \"label\").unique()\n",
    "pdf = df.to_pandas()\n",
    "X = pdf[\"product_text\"].astype(str).values\n",
    "y = pdf[\"label\"].astype(int).values\n",
    "\n",
    "X_tr, X_tmp, y_tr, y_tmp = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "X_val, X_te,  y_val, y_te = train_test_split(X_tmp, y_tmp, test_size=0.50, random_state=42, stratify=y_tmp)\n",
    "\n",
    "# 2) Vectorize and train\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=2)\n",
    "Xtr = tfidf.fit_transform(X_tr)\n",
    "Xv  = tfidf.transform(X_val)\n",
    "Xt  = tfidf.transform(X_te)\n",
    "\n",
    "clf = LogisticRegression(max_iter=2000, class_weight=\"balanced\")\n",
    "clf.fit(Xtr, y_tr)\n",
    "\n",
    "# 3) Evaluate at default threshold 0.5\n",
    "proba_val = clf.predict_proba(Xv)[:, 1]\n",
    "proba_te  = clf.predict_proba(Xt)[:, 1]\n",
    "\n",
    "def metrics_at_threshold(y_true, scores, thr):\n",
    "    preds = (scores >= thr).astype(int)\n",
    "    return {\n",
    "        \"thr\": thr,\n",
    "        \"acc\": accuracy_score(y_true, preds),\n",
    "        \"macro_f1\": f1_score(y_true, preds, average=\"macro\"),\n",
    "        \"report\": classification_report(y_true, preds, digits=3),\n",
    "        \"cm\": confusion_matrix(y_true, preds)  # rows=true [0,1], cols=pred [0,1]\n",
    "    }\n",
    "\n",
    "m_default_val = metrics_at_threshold(y_val, proba_val, 0.5)\n",
    "m_default_te  = metrics_at_threshold(y_te,  proba_te,  0.5)\n",
    "\n",
    "print(\"Default threshold (0.5) — validation:\")\n",
    "print(\"  acc:\", round(m_default_val[\"acc\"],4), \"macro F1:\", round(m_default_val[\"macro_f1\"],4))\n",
    "print(\"  confusion matrix:\\n\", m_default_val[\"cm\"])\n",
    "print(\"\\nDefault threshold (0.5) — test:\")\n",
    "print(\"  acc:\", round(m_default_te[\"acc\"],4), \"macro F1:\", round(m_default_te[\"macro_f1\"],4))\n",
    "print(\"  confusion matrix:\\n\", m_default_te[\"cm\"])\n",
    "\n",
    "# 4) Find a better threshold on validation (optimize macro-F1 and accuracy separately)\n",
    "grid = np.linspace(0.10, 0.90, 33)  # coarse search; enough for guidance\n",
    "scores_val = []\n",
    "for t in grid:\n",
    "    preds = (proba_val >= t).astype(int)\n",
    "    scores_val.append((t,\n",
    "                       accuracy_score(y_val, preds),\n",
    "                       f1_score(y_val, preds, average=\"macro\")))\n",
    "best_by_acc = max(scores_val, key=lambda x: x[1])\n",
    "best_by_f1  = max(scores_val, key=lambda x: x[2])\n",
    "\n",
    "print(\"\\nBest threshold by validation accuracy:\", round(best_by_acc[0],3),\n",
    "      \"-> acc:\", round(best_by_acc[1],4), \"macro F1:\", round(best_by_acc[2],4))\n",
    "print(\"Best threshold by validation macro-F1:\", round(best_by_f1[0],3),\n",
    "      \"-> acc:\", round(best_by_f1[1],4), \"macro F1:\", round(best_by_f1[2],4))\n",
    "\n",
    "# 5) Evaluate tuned thresholds on the test set\n",
    "m_acc_te = metrics_at_threshold(y_te, proba_te, best_by_acc[0])\n",
    "m_f1_te  = metrics_at_threshold(y_te, proba_te, best_by_f1[0])\n",
    "\n",
    "print(\"\\nTuned-by-accuracy — test:\")\n",
    "print(\"  thr:\", round(m_acc_te[\"thr\"],3), \"acc:\", round(m_acc_te[\"acc\"],4),\n",
    "      \"macro F1:\", round(m_acc_te[\"macro_f1\"],4))\n",
    "print(\"  confusion matrix:\\n\", m_acc_te[\"cm\"])\n",
    "\n",
    "print(\"\\nTuned-by-macro-F1 — test:\")\n",
    "print(\"  thr:\", round(m_f1_te[\"thr\"],3), \"acc:\", round(m_f1_te[\"acc\"],4),\n",
    "      \"macro F1:\", round(m_f1_te[\"macro_f1\"],4))\n",
    "print(\"  confusion matrix:\\n\", m_f1_te[\"cm\"])\n",
    "\n",
    "# 6) Show a few False Positives/Negatives at the chosen F1-threshold\n",
    "thr = best_by_f1[0]\n",
    "preds_te = (proba_te >= thr).astype(int)\n",
    "test_pd = pd.DataFrame({\"text\": X_te, \"y\": y_te, \"score\": proba_te, \"pred\": preds_te})\n",
    "\n",
    "fp = test_pd[(test_pd.y==0) & (test_pd.pred==1)].sort_values(\"score\", ascending=False).head(5)\n",
    "fn = test_pd[(test_pd.y==1) & (test_pd.pred==0)].sort_values(\"score\", ascending=True).head(5)\n",
    "\n",
    "print(\"\\nTop 5 false positives (pred=1 but y=0):\")\n",
    "print(fp[[\"score\",\"text\"]].to_string(index=False, max_colwidth=80))\n",
    "\n",
    "print(\"\\nTop 5 false negatives (pred=0 but y=1):\")\n",
    "print(fn[[\"score\",\"text\"]].to_string(index=False, max_colwidth=80))\n",
    "\n",
    "#  average precision (PR-AUC) on test set stays the same as before since it's threshold-free\n",
    "print(\"\\nTest PR-AUC (avg precision):\", round(average_precision_score(y_te, proba_te), 4))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashion-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
