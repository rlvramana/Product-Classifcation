{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8296d584",
   "metadata": {},
   "source": [
    "#### This is the second iteration of BERT tuning to see if we can imporove it a bit further, if we cannot we will settle for the best model we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b85c26d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation\n",
      "PROCESSED_DATA_DIR: /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation/data/processed\n"
     ]
    }
   ],
   "source": [
    "# 06b_bert_finetune_weighted.ipynb\n",
    "# Cell 1 â€“ set up project root, src path, and config\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Detect project root (assuming this notebook lives in notebooks/)\n",
    "cwd = Path.cwd().resolve()\n",
    "if cwd.name == \"notebooks\":\n",
    "    PROJECT_ROOT = cwd.parent\n",
    "else:\n",
    "    PROJECT_ROOT = cwd\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "# Make sure src/ is on the Python path\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "if not SRC_DIR.is_dir():\n",
    "    raise FileNotFoundError(f\"'src' folder not found at {SRC_DIR}\")\n",
    "\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# Import shared config (paths)\n",
    "from config import PROCESSED_DATA_DIR\n",
    "\n",
    "print(\"PROCESSED_DATA_DIR:\", PROCESSED_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdc76020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (19767, 10)\n",
      "\n",
      "Split counts:\n",
      "split\n",
      "train    13961\n",
      "val       3262\n",
      "test      2544\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Columns:\n",
      "['event_id', 'event_type', 'start_time_local', 'remove_amazon', 'month', 'product_text_raw', 'product_text_norm', 'label_raw', 'label', 'split']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_text_raw</th>\n",
       "      <th>product_text_norm</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001B 3000A Car Jump Starter Battery Pack (up t...</td>\n",
       "      <td>001b 3000a car jump starter battery pack up to...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>012 Jump Starter Battery Pack, 4000A Peak Car ...</td>\n",
       "      <td>012 jump starter battery pack 4000a peak car b...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/2 Ct Diamond Stud Earrings 14k Yellow Gold F...</td>\n",
       "      <td>1 2 ct diamond stud earrings 14k yellow gold f...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-2 Pairs 925 Sterling Silver Mens Earrings Cu...</td>\n",
       "      <td>1 2 pairs 925 sterling silver mens earrings cu...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/2\"\" x 18\"\" Zirconia Sanding Belts for Belt S...</td>\n",
       "      <td>1 2 x 18 zirconia sanding belts for belt sande...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    product_text_raw  \\\n",
       "0  001B 3000A Car Jump Starter Battery Pack (up t...   \n",
       "1  012 Jump Starter Battery Pack, 4000A Peak Car ...   \n",
       "2  1/2 Ct Diamond Stud Earrings 14k Yellow Gold F...   \n",
       "3  1-2 Pairs 925 Sterling Silver Mens Earrings Cu...   \n",
       "4  1/2\"\" x 18\"\" Zirconia Sanding Belts for Belt S...   \n",
       "\n",
       "                                   product_text_norm  label  split  \n",
       "0  001b 3000a car jump starter battery pack up to...      0  train  \n",
       "1  012 jump starter battery pack 4000a peak car b...      0  train  \n",
       "2  1 2 ct diamond stud earrings 14k yellow gold f...      1   test  \n",
       "3  1 2 pairs 925 sterling silver mens earrings cu...      1  train  \n",
       "4  1 2 x 18 zirconia sanding belts for belt sande...      0  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 2 â€“ load processed products and inspect splits\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "products_path = PROCESSED_DATA_DIR / \"products_with_splits.parquet\"\n",
    "df = pd.read_parquet(products_path)\n",
    "\n",
    "print(\"Full dataset shape:\", df.shape)\n",
    "print(\"\\nSplit counts:\")\n",
    "print(df[\"split\"].value_counts())\n",
    "\n",
    "print(\"\\nColumns:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Quick peek at the key columns\n",
    "df[[\"product_text_raw\", \"product_text_norm\", \"label\", \"split\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1f0e45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name: bert_fashion_weighted\n",
      "Model output dir: /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation/models/bert_fashion_weighted\n",
      "MODEL_NAME: bert-base-uncased\n",
      "MAX_LENGTH: 64\n",
      "CLASS_WEIGHTS: [2.0, 1.0]\n",
      "\n",
      "Sample text: 001b 3000a car jump starter battery pack up to 9 0l gas and 7 0l diesel engine 12v car battery charger jump box with usb ...\n",
      "input_ids length: 64\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 â€“ experiment config and tokenizer setup\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# New experiment name so we DO NOT overwrite the baseline model\n",
    "EXPERIMENT_NAME = \"bert_fashion_weighted\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"models\" / EXPERIMENT_NAME\n",
    "\n",
    "print(\"Experiment name:\", EXPERIMENT_NAME)\n",
    "print(\"Model output dir:\", OUTPUT_DIR)\n",
    "\n",
    "# BERT backbone and sequence length (same as baseline)\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "MAX_LENGTH = 64\n",
    "\n",
    "# Class weights: [weight_for_label_0, weight_for_label_1]\n",
    "# We care more about non-fashion (0), so we give it a higher weight.\n",
    "CLASS_WEIGHTS = torch.tensor([2.0, 1.0])\n",
    "\n",
    "print(\"MODEL_NAME:\", MODEL_NAME)\n",
    "print(\"MAX_LENGTH:\", MAX_LENGTH)\n",
    "print(\"CLASS_WEIGHTS:\", CLASS_WEIGHTS.tolist())\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Quick sanity check on tokenization length\n",
    "sample_text = df.loc[0, \"product_text_norm\"]\n",
    "enc = tokenizer(\n",
    "    sample_text,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=MAX_LENGTH,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "print(\"\\nSample text:\", sample_text[:120], \"...\")\n",
    "print(\"input_ids length:\", enc[\"input_ids\"].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f303cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (13961, 10)\n",
      "Val shape  : (3262, 10)\n",
      "Test shape : (2544, 10)\n",
      "\n",
      "Raw HF datasets:\n",
      "  train: Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 13961\n",
      "})\n",
      "  val  : Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 3262\n",
      "})\n",
      "  test : Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 2544\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13961/13961 [00:00<00:00, 29887.14 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3262/3262 [00:00<00:00, 39820.89 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2544/2544 [00:00<00:00, 38513.33 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenized HF datasets:\n",
      "  train_tok: Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 13961\n",
      "})\n",
      "  val_tok  : Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 3262\n",
      "})\n",
      "  test_tok : Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 2544\n",
      "})\n",
      "\n",
      "Example keys: dict_keys(['label', 'input_ids', 'token_type_ids', 'attention_mask'])\n",
      "input_ids length: 64\n",
      "label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 â€“ build HF datasets and tokenize (same splits as baseline)\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# 1. Split the dataframe into train / val / test\n",
    "train_df = df[df[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "val_df   = df[df[\"split\"] == \"val\"].reset_index(drop=True)\n",
    "test_df  = df[df[\"split\"] == \"test\"].reset_index(drop=True)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Val shape  :\", val_df.shape)\n",
    "print(\"Test shape :\", test_df.shape)\n",
    "\n",
    "# 2. Create Hugging Face Dataset objects\n",
    "def df_to_hf(ds_df):\n",
    "    return Dataset.from_pandas(\n",
    "        ds_df[[\"product_text_norm\", \"label\"]].rename(\n",
    "            columns={\"product_text_norm\": \"text\"}\n",
    "        )\n",
    "    )\n",
    "\n",
    "train_hf = df_to_hf(train_df)\n",
    "val_hf   = df_to_hf(val_df)\n",
    "test_hf  = df_to_hf(test_df)\n",
    "\n",
    "print(\"\\nRaw HF datasets:\")\n",
    "print(\"  train:\", train_hf)\n",
    "print(\"  val  :\", val_hf)\n",
    "print(\"  test :\", test_hf)\n",
    "\n",
    "# 3. Tokenization function\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "    )\n",
    "\n",
    "# 4. Apply tokenization\n",
    "train_tok = train_hf.map(tokenize_batch, batched=True)\n",
    "val_tok   = val_hf.map(tokenize_batch, batched=True)\n",
    "test_tok  = test_hf.map(tokenize_batch, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "cols = [\"input_ids\", \"attention_mask\", \"token_type_ids\", \"label\"]\n",
    "train_tok.set_format(type=\"torch\", columns=cols)\n",
    "val_tok.set_format(type=\"torch\", columns=cols)\n",
    "test_tok.set_format(type=\"torch\", columns=cols)\n",
    "\n",
    "print(\"\\nTokenized HF datasets:\")\n",
    "print(\"  train_tok:\", train_tok)\n",
    "print(\"  val_tok  :\", val_tok)\n",
    "print(\"  test_tok :\", test_tok)\n",
    "\n",
    "# Quick sanity check on one example\n",
    "example = train_tok[0]\n",
    "print(\"\\nExample keys:\", example.keys())\n",
    "print(\"input_ids length:\", len(example[\"input_ids\"]))\n",
    "print(\"label:\", example[\"label\"].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88ed929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer ready. Output dir will be: /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation/models/bert_fashion_weighted\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 â€“ define weighted BERT model, Trainer, and training args\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Load base BERT classification model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,\n",
    ")\n",
    "\n",
    "# Move class weights to same device later (in compute_loss)\n",
    "CLASS_WEIGHTS = CLASS_WEIGHTS.to(torch.float32)\n",
    "\n",
    "# Metrics function (same as baseline, simple accuracy + F1)\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"precision\": precision_score(labels, preds),\n",
    "        \"recall\": recall_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds),\n",
    "    }\n",
    "\n",
    "# Custom Trainer to use weighted cross-entropy\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # Standard forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        # Weighted cross-entropy: weight[0] for non-fashion, weight[1] for fashion\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=CLASS_WEIGHTS.to(logits.device))\n",
    "        loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Training arguments â€“ note output_dir is the NEW experiment folder\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(OUTPUT_DIR),\n",
    "    num_train_epochs=3,              # same as baseline\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_tok,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Trainer ready. Output dir will be:\", training_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea651ed",
   "metadata": {},
   "source": [
    "#### \tâ€¢\tIn this run we trained a second BERT model (bert_fashion_weighted) with the same architecture, tokenizer, data splits, max length (64), learning rate schedule, batch size, and number of epochs as the original bert_fashion model.\n",
    "####\tâ€¢\tThe only change was the loss weighting: we set class_weights = [2.0, 1.0], giving class 0 (non-fashion, the minority class) twice the weight of class 1 (fashion). This makes the model â€œcare moreâ€ about mistakes on non-fashion items and is aimed at reducing cases where non-fashion products are predicted as fashion.\n",
    "####\tâ€¢\tAll evaluation and QA will reuse the same validation/test splits and the same 100-row unlabeled QA sample, so we can directly compare the original BERT model, the weighted BERT model, and the logistic baseline on exactly the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9035ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2619 [00:00<?, ?it/s]/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "  2%|â–         | 51/2619 [00:14<08:21,  5.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3672, 'grad_norm': 8.153903007507324, 'learning_rate': 1.9618174875906837e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 101/2619 [00:23<08:07,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2663, 'grad_norm': 6.130841255187988, 'learning_rate': 1.923634975181367e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 151/2619 [00:33<07:53,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2632, 'grad_norm': 11.1942138671875, 'learning_rate': 1.8854524627720504e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 201/2619 [00:42<07:50,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2033, 'grad_norm': 0.44448909163475037, 'learning_rate': 1.847269950362734e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–‰         | 251/2619 [00:52<07:27,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2039, 'grad_norm': 8.81950569152832, 'learning_rate': 1.8090874379534175e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆâ–        | 301/2619 [01:02<07:21,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1215, 'grad_norm': 2.2943639755249023, 'learning_rate': 1.770904925544101e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 351/2619 [01:11<07:32,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1705, 'grad_norm': 4.287690162658691, 'learning_rate': 1.7327224131347845e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 401/2619 [01:21<07:52,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1729, 'grad_norm': 4.8274993896484375, 'learning_rate': 1.694539900725468e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 451/2619 [01:31<06:55,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0885, 'grad_norm': 0.1430259793996811, 'learning_rate': 1.6563573883161516e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–‰        | 501/2619 [01:41<06:44,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1612, 'grad_norm': 28.638914108276367, 'learning_rate': 1.6181748759068348e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆ        | 551/2619 [01:50<06:34,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.144, 'grad_norm': 1.1454479694366455, 'learning_rate': 1.5799923634975183e-05, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 601/2619 [02:00<06:27,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.132, 'grad_norm': 0.4201792776584625, 'learning_rate': 1.541809851088202e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–       | 651/2619 [02:09<06:17,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1355, 'grad_norm': 1.8168890476226807, 'learning_rate': 1.503627338678885e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 701/2619 [02:19<06:07,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1185, 'grad_norm': 7.890887260437012, 'learning_rate': 1.4654448262695686e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–Š       | 751/2619 [02:28<05:58,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.133, 'grad_norm': 6.558115482330322, 'learning_rate': 1.4272623138602521e-05, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆ       | 801/2619 [02:38<05:47,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0975, 'grad_norm': 14.904824256896973, 'learning_rate': 1.3890798014509356e-05, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 851/2619 [02:48<05:53,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1044, 'grad_norm': 31.075958251953125, 'learning_rate': 1.350897289041619e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 873/2619 [03:03<10:14,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1155150756239891, 'eval_accuracy': 0.9754751686082158, 'eval_precision': 0.9842632331902719, 'eval_recall': 0.9870875179340028, 'eval_f1': 0.9856733524355301, 'eval_runtime': 9.8447, 'eval_samples_per_second': 331.346, 'eval_steps_per_second': 10.361, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 901/2619 [03:10<05:46,  4.96it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0768, 'grad_norm': 0.0632750540971756, 'learning_rate': 1.3127147766323025e-05, 'epoch': 1.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–‹      | 951/2619 [03:20<05:42,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1243, 'grad_norm': 0.09767290949821472, 'learning_rate': 1.274532264222986e-05, 'epoch': 1.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1001/2619 [03:30<05:18,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0665, 'grad_norm': 0.09852530807256699, 'learning_rate': 1.2363497518136694e-05, 'epoch': 1.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1051/2619 [03:40<04:59,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0656, 'grad_norm': 0.03215698152780533, 'learning_rate': 1.198167239404353e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1101/2619 [03:49<04:49,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0548, 'grad_norm': 0.04309866577386856, 'learning_rate': 1.1599847269950365e-05, 'epoch': 1.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1151/2619 [03:59<04:39,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0564, 'grad_norm': 0.040597353130578995, 'learning_rate': 1.1218022145857198e-05, 'epoch': 1.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1201/2619 [04:08<04:29,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0667, 'grad_norm': 0.19712355732917786, 'learning_rate': 1.0836197021764032e-05, 'epoch': 1.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1251/2619 [04:18<04:19,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1052, 'grad_norm': 0.04654578119516373, 'learning_rate': 1.0454371897670867e-05, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1301/2619 [04:27<04:10,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0605, 'grad_norm': 0.07568784058094025, 'learning_rate': 1.0072546773577703e-05, 'epoch': 1.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1351/2619 [04:37<04:01,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0737, 'grad_norm': 0.023630574345588684, 'learning_rate': 9.690721649484536e-06, 'epoch': 1.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1401/2619 [04:46<03:51,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.085, 'grad_norm': 0.18155086040496826, 'learning_rate': 9.308896525391371e-06, 'epoch': 1.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1451/2619 [04:56<03:43,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0402, 'grad_norm': 0.3505565822124481, 'learning_rate': 8.927071401298207e-06, 'epoch': 1.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1501/2619 [05:05<03:33,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0462, 'grad_norm': 5.784054279327393, 'learning_rate': 8.54524627720504e-06, 'epoch': 1.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1551/2619 [05:15<03:23,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0854, 'grad_norm': 0.058844003826379776, 'learning_rate': 8.163421153111876e-06, 'epoch': 1.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1601/2619 [05:24<03:13,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0346, 'grad_norm': 0.024881185963749886, 'learning_rate': 7.78159602901871e-06, 'epoch': 1.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1651/2619 [05:34<03:05,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.076, 'grad_norm': 0.058833908289670944, 'learning_rate': 7.3997709049255455e-06, 'epoch': 1.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1701/2619 [05:43<02:54,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0938, 'grad_norm': 4.490511894226074, 'learning_rate': 7.017945780832379e-06, 'epoch': 1.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1746/2619 [06:01<02:32,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10024674236774445, 'eval_accuracy': 0.9809932556713673, 'eval_precision': 0.9917027417027418, 'eval_recall': 0.9860114777618364, 'eval_f1': 0.9888489208633093, 'eval_runtime': 9.2705, 'eval_samples_per_second': 351.868, 'eval_steps_per_second': 11.003, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1751/2619 [06:03<13:43,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0363, 'grad_norm': 0.5439833998680115, 'learning_rate': 6.636120656739214e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1801/2619 [06:13<02:35,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0763, 'grad_norm': 0.9959256052970886, 'learning_rate': 6.254295532646049e-06, 'epoch': 2.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1851/2619 [06:22<02:26,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0476, 'grad_norm': 2.882087469100952, 'learning_rate': 5.8724704085528825e-06, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1901/2619 [06:32<02:16,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0369, 'grad_norm': 0.1360497772693634, 'learning_rate': 5.490645284459718e-06, 'epoch': 2.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1951/2619 [06:41<02:13,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0419, 'grad_norm': 0.01664390228688717, 'learning_rate': 5.108820160366552e-06, 'epoch': 2.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2001/2619 [06:51<01:57,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0329, 'grad_norm': 0.01887540891766548, 'learning_rate': 4.7269950362733875e-06, 'epoch': 2.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2051/2619 [07:01<01:50,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0316, 'grad_norm': 0.019533546641469002, 'learning_rate': 4.345169912180222e-06, 'epoch': 2.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2101/2619 [07:10<01:38,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0337, 'grad_norm': 0.043289847671985626, 'learning_rate': 3.9633447880870564e-06, 'epoch': 2.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2151/2619 [07:20<01:29,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0158, 'grad_norm': 0.05001983791589737, 'learning_rate': 3.581519663993891e-06, 'epoch': 2.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2201/2619 [07:30<01:19,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.036, 'grad_norm': 2.05403208732605, 'learning_rate': 3.1996945399007258e-06, 'epoch': 2.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2251/2619 [07:39<01:09,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0258, 'grad_norm': 0.005883615929633379, 'learning_rate': 2.8178694158075602e-06, 'epoch': 2.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2301/2619 [07:49<01:00,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0289, 'grad_norm': 0.03987772762775421, 'learning_rate': 2.436044291714395e-06, 'epoch': 2.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2351/2619 [07:59<00:51,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0254, 'grad_norm': 0.010568277910351753, 'learning_rate': 2.0542191676212296e-06, 'epoch': 2.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2401/2619 [08:08<00:42,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0379, 'grad_norm': 0.05835536867380142, 'learning_rate': 1.6723940435280642e-06, 'epoch': 2.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2451/2619 [08:18<00:31,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0313, 'grad_norm': 0.004373618867248297, 'learning_rate': 1.2905689194348989e-06, 'epoch': 2.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2501/2619 [08:27<00:22,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0107, 'grad_norm': 0.0456349141895771, 'learning_rate': 9.087437953417336e-07, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2551/2619 [08:37<00:12,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0406, 'grad_norm': 0.02956571616232395, 'learning_rate': 5.269186712485682e-07, 'epoch': 2.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2601/2619 [08:47<00:03,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0473, 'grad_norm': 30.283830642700195, 'learning_rate': 1.4509354715540282e-07, 'epoch': 2.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2619/2619 [08:50<00:00,  5.65it/s]/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                   \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2619/2619 [09:01<00:00,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10478895157575607, 'eval_accuracy': 0.9834457388105456, 'eval_precision': 0.992790194664744, 'eval_recall': 0.9878048780487805, 'eval_f1': 0.9902912621359223, 'eval_runtime': 9.2842, 'eval_samples_per_second': 351.35, 'eval_steps_per_second': 10.986, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2619/2619 [09:02<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 542.9006, 'train_samples_per_second': 77.147, 'train_steps_per_second': 4.824, 'train_loss': 0.09088216179789091, 'epoch': 3.0}\n",
      "\n",
      "Training finished.\n",
      "Best model saved in: /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation/models/bert_fashion_weighted\n",
      "\n",
      "=== Evaluation on validation split ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:09<00:00, 11.16it/s]\n",
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10478895157575607, 'eval_accuracy': 0.9834457388105456, 'eval_precision': 0.992790194664744, 'eval_recall': 0.9878048780487805, 'eval_f1': 0.9902912621359223, 'eval_runtime': 9.2634, 'eval_samples_per_second': 352.137, 'eval_steps_per_second': 11.011, 'epoch': 3.0}\n",
      "\n",
      "=== Evaluation on test split ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:07<00:00, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20732198655605316, 'eval_accuracy': 0.9713050314465409, 'eval_precision': 0.9810066476733144, 'eval_recall': 0.9842782277274893, 'eval_f1': 0.9826397146254459, 'eval_runtime': 7.209, 'eval_samples_per_second': 352.892, 'eval_steps_per_second': 11.097, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 â€“ train weighted BERT and do a quick sanity eval\n",
    "\n",
    "# Train the model (this will create models/bert_fashion_weighted/)\n",
    "train_result = trainer.train()\n",
    "\n",
    "# Explicitly save model + tokenizer to the new experiment folder\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "print(\"\\nTraining finished.\")\n",
    "print(\"Best model saved in:\", OUTPUT_DIR)\n",
    "\n",
    "# Quick sanity check on val and test (no plots, just numbers)\n",
    "print(\"\\n=== Evaluation on validation split ===\")\n",
    "val_metrics = trainer.evaluate(eval_dataset=val_tok)\n",
    "print(val_metrics)\n",
    "\n",
    "print(\"\\n=== Evaluation on test split ===\")\n",
    "test_metrics = trainer.evaluate(eval_dataset=test_tok)\n",
    "print(test_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashion-bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
