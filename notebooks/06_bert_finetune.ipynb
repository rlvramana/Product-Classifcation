{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664d1e74",
   "metadata": {},
   "source": [
    "#### 06 - BERT baseline for fashion vs non-fashion\n",
    "\n",
    "This notebook fine-tunes a transformer-based classifier (BERT) on the\n",
    "same cleaned dataset and time-aware splits used for the TF-IDF + logistic baseline:\n",
    "\n",
    "- Input text: `product_text_norm`\n",
    "- Labels: `label` (0 = non-fashion, 1 = fashion)\n",
    "- Splits: `train`, `val`, `test` from `products_with_splits.parquet`\n",
    "\n",
    "We will:\n",
    "1. Load the processed dataset and splits.\n",
    "2. Tokenize texts with a pre-trained transformer tokenizer.\n",
    "3. Fine-tune the model with Hugging Face `Trainer`.\n",
    "4. Plot training and validation loss curves to check for overfitting.\n",
    "5. Evaluate on validation and test and later tune a probability threshold (as we did for logistic regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d77a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation\n",
      "PROCESSED_DATA_DIR: /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation/data/processed\n",
      "Full dataset shape: (19767, 10)\n",
      "\n",
      "Splits:\n",
      "split\n",
      "test      2544\n",
      "train    13961\n",
      "val       3262\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Labels:\n",
      "label\n",
      "0     3165\n",
      "1    16602\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_text_raw</th>\n",
       "      <th>product_text_norm</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001B 3000A Car Jump Starter Battery Pack (up t...</td>\n",
       "      <td>001b 3000a car jump starter battery pack up to...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>012 Jump Starter Battery Pack, 4000A Peak Car ...</td>\n",
       "      <td>012 jump starter battery pack 4000a peak car b...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/2 Ct Diamond Stud Earrings 14k Yellow Gold F...</td>\n",
       "      <td>1 2 ct diamond stud earrings 14k yellow gold f...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-2 Pairs 925 Sterling Silver Mens Earrings Cu...</td>\n",
       "      <td>1 2 pairs 925 sterling silver mens earrings cu...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/2\"\" x 18\"\" Zirconia Sanding Belts for Belt S...</td>\n",
       "      <td>1 2 x 18 zirconia sanding belts for belt sande...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5 Gram x 50 Vial Convenient Super Glue, Wegl...</td>\n",
       "      <td>1 5 gram x 50 vial convenient super glue wegla...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/6 Scale Female Clothes, Female Black Leather...</td>\n",
       "      <td>1 6 scale female clothes female black leather ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/6 Scale Female Clothes, Female Sports Underw...</td>\n",
       "      <td>1 6 scale female clothes female sports underwe...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/6 Scale Female Clothes, Female Sports Underw...</td>\n",
       "      <td>1 6 scale female clothes female sports underwe...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.75mm Normal PLA 4 Most Basic Colors Bundle P...</td>\n",
       "      <td>1 75mm normal pla 4 most basic colors bundle p...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    product_text_raw  \\\n",
       "0  001B 3000A Car Jump Starter Battery Pack (up t...   \n",
       "1  012 Jump Starter Battery Pack, 4000A Peak Car ...   \n",
       "2  1/2 Ct Diamond Stud Earrings 14k Yellow Gold F...   \n",
       "3  1-2 Pairs 925 Sterling Silver Mens Earrings Cu...   \n",
       "4  1/2\"\" x 18\"\" Zirconia Sanding Belts for Belt S...   \n",
       "5  1.5 Gram x 50 Vial Convenient Super Glue, Wegl...   \n",
       "6  1/6 Scale Female Clothes, Female Black Leather...   \n",
       "7  1/6 Scale Female Clothes, Female Sports Underw...   \n",
       "8  1/6 Scale Female Clothes, Female Sports Underw...   \n",
       "9  1.75mm Normal PLA 4 Most Basic Colors Bundle P...   \n",
       "\n",
       "                                   product_text_norm  label  split  \n",
       "0  001b 3000a car jump starter battery pack up to...      0  train  \n",
       "1  012 jump starter battery pack 4000a peak car b...      0  train  \n",
       "2  1 2 ct diamond stud earrings 14k yellow gold f...      1   test  \n",
       "3  1 2 pairs 925 sterling silver mens earrings cu...      1  train  \n",
       "4  1 2 x 18 zirconia sanding belts for belt sande...      0  train  \n",
       "5  1 5 gram x 50 vial convenient super glue wegla...      0  train  \n",
       "6  1 6 scale female clothes female black leather ...      1  train  \n",
       "7  1 6 scale female clothes female sports underwe...      1  train  \n",
       "8  1 6 scale female clothes female sports underwe...      1  train  \n",
       "9  1 75mm normal pla 4 most basic colors bundle p...      0  train  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up project paths, imports, and load products_with_splits\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Find project root (folder containing \"src\") and add src to sys.path\n",
    "cwd = Path.cwd()\n",
    "project_root = None\n",
    "for path in [cwd, *cwd.parents]:\n",
    "    if (path / \"src\").is_dir():\n",
    "        project_root = path\n",
    "        break\n",
    "\n",
    "if project_root is None:\n",
    "    raise FileNotFoundError(\"Could not find project root containing 'src' folder.\")\n",
    "\n",
    "SRC_DIR = project_root / \"src\"\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "from config import PROCESSED_DATA_DIR\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "print(\"PROCESSED_DATA_DIR:\", PROCESSED_DATA_DIR)\n",
    "\n",
    "# 2) Load processed dataset with splits\n",
    "data_path = PROCESSED_DATA_DIR / \"products_with_splits.parquet\"\n",
    "df = pd.read_parquet(data_path)\n",
    "\n",
    "print(\"Full dataset shape:\", df.shape)\n",
    "print(\"\\nSplits:\")\n",
    "print(df[\"split\"].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nLabels:\")\n",
    "print(df[\"label\"].value_counts().sort_index())\n",
    "\n",
    "df[[\"product_text_raw\", \"product_text_norm\", \"label\", \"split\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2f05d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "  train: (13961, 10)\n",
      "  val  : (3262, 10)\n",
      "  test : (2544, 10)\n",
      "\n",
      "Class balance in train (0=non-fashion, 1=fashion):\n",
      "  label=0: 2246 rows (16.09%)\n",
      "  label=1: 11715 rows (83.91%)\n",
      "\n",
      "Class balance in val (0=non-fashion, 1=fashion):\n",
      "  label=0: 474 rows (14.53%)\n",
      "  label=1: 2788 rows (85.47%)\n",
      "\n",
      "Class balance in test (0=non-fashion, 1=fashion):\n",
      "  label=0: 445 rows (17.49%)\n",
      "  label=1: 2099 rows (82.51%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_text_raw</th>\n",
       "      <th>product_text_norm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001B 3000A Car Jump Starter Battery Pack (up t...</td>\n",
       "      <td>001b 3000a car jump starter battery pack up to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>012 Jump Starter Battery Pack, 4000A Peak Car ...</td>\n",
       "      <td>012 jump starter battery pack 4000a peak car b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-2 Pairs 925 Sterling Silver Mens Earrings Cu...</td>\n",
       "      <td>1 2 pairs 925 sterling silver mens earrings cu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/2\"\" x 18\"\" Zirconia Sanding Belts for Belt S...</td>\n",
       "      <td>1 2 x 18 zirconia sanding belts for belt sande...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.5 Gram x 50 Vial Convenient Super Glue, Wegl...</td>\n",
       "      <td>1 5 gram x 50 vial convenient super glue wegla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    product_text_raw  \\\n",
       "0  001B 3000A Car Jump Starter Battery Pack (up t...   \n",
       "1  012 Jump Starter Battery Pack, 4000A Peak Car ...   \n",
       "3  1-2 Pairs 925 Sterling Silver Mens Earrings Cu...   \n",
       "4  1/2\"\" x 18\"\" Zirconia Sanding Belts for Belt S...   \n",
       "5  1.5 Gram x 50 Vial Convenient Super Glue, Wegl...   \n",
       "\n",
       "                                   product_text_norm  label  \n",
       "0  001b 3000a car jump starter battery pack up to...      0  \n",
       "1  012 jump starter battery pack 4000a peak car b...      0  \n",
       "3  1 2 pairs 925 sterling silver mens earrings cu...      1  \n",
       "4  1 2 x 18 zirconia sanding belts for belt sande...      0  \n",
       "5  1 5 gram x 50 vial convenient super glue wegla...      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train / val / test DataFrames for BERT fine-tuning\n",
    "\n",
    "df_train = df[df[\"split\"] == \"train\"].copy()\n",
    "df_val   = df[df[\"split\"] == \"val\"].copy()\n",
    "df_test  = df[df[\"split\"] == \"test\"].copy()\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  train:\", df_train.shape)\n",
    "print(\"  val  :\", df_val.shape)\n",
    "print(\"  test :\", df_test.shape)\n",
    "\n",
    "def print_class_balance(name, subdf):\n",
    "    counts = subdf[\"label\"].value_counts().sort_index()\n",
    "    pct = subdf[\"label\"].value_counts(normalize=True).sort_index() * 100\n",
    "    print(f\"\\nClass balance in {name} (0=non-fashion, 1=fashion):\")\n",
    "    for k in counts.index:\n",
    "        print(f\"  label={k}: {counts[k]} rows ({pct[k]:.2f}%)\")\n",
    "\n",
    "print_class_balance(\"train\", df_train)\n",
    "print_class_balance(\"val\", df_val)\n",
    "print_class_balance(\"test\", df_test)\n",
    "\n",
    "df_train[[\"product_text_raw\", \"product_text_norm\", \"label\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08007b81",
   "metadata": {},
   "source": [
    "#### BERT model and tokenizer\n",
    "\n",
    "We use the `bert-base-uncased` checkpoint from Hugging Face. The tokenizer will turn\n",
    "`product_text_norm` strings into input IDs and attention masks for BERT. Product\n",
    "titles are short, so we cap sequence length at 64 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc7cab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: bert-base-uncased\n",
      "Tokenizer vocab size: 30522\n",
      "Max length: 64\n",
      "\n",
      "Sample text: 001b 3000a car jump starter battery pack up to 9 0l gas and 7 0l diesel engine 12v car battery charger jump box with usb 3 0 power bank\n",
      "input_ids length: 64\n",
      "\n",
      "Sample text: 012 jump starter battery pack 4000a peak car battery charger jump starter for up to 10 0l gas or 8 0l diesel engine 12v car jumper starter portable with full lcd screen led light usb\n",
      "input_ids length: 64\n",
      "\n",
      "Sample text: 1 2 pairs 925 sterling silver mens earrings cubic zirconia halo stud earrings for men 18k gold plated heart round square cut cz stud earrings set for women men\n",
      "input_ids length: 64\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Choose the BERT checkpoint\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "MAX_LENGTH = 64  # max tokens per product title (truncates very long titles)\n",
    "\n",
    "print(\"Using model:\", MODEL_NAME)\n",
    "print(\"Tokenizer vocab size:\", tokenizer.vocab_size)\n",
    "print(\"Max length:\", MAX_LENGTH)\n",
    "\n",
    "# Quick sanity check on a couple of sample texts\n",
    "for txt in df_train[\"product_text_norm\"].head(3).tolist():\n",
    "    enc = tokenizer(\n",
    "        txt,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "    )\n",
    "    print(\"\\nSample text:\", txt)\n",
    "    print(\"input_ids length:\", len(enc[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08fd233",
   "metadata": {},
   "source": [
    "\tâ€¢\tConverts each split into a Hugging Face Dataset with text and label.\n",
    "\tâ€¢\tRuns the BERT tokenizer on all texts with padding/truncation to MAX_LENGTH.\n",
    "\tâ€¢\tRenames label â†’ labels because Trainer expects that column.\n",
    "\tâ€¢\tShows a sample tokenized item so you can see what BERT will receive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c64f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw HF datasets:\n",
      "  train: Dataset({\n",
      "    features: ['text', 'label', '__index_level_0__'],\n",
      "    num_rows: 13961\n",
      "})\n",
      "  val  : Dataset({\n",
      "    features: ['text', 'label', '__index_level_0__'],\n",
      "    num_rows: 3262\n",
      "})\n",
      "  test : Dataset({\n",
      "    features: ['text', 'label', '__index_level_0__'],\n",
      "    num_rows: 2544\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13961/13961 [00:00<00:00, 32237.57 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3262/3262 [00:00<00:00, 34406.34 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2544/2544 [00:00<00:00, 39503.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenized HF datasets:\n",
      "  train_tok: Dataset({\n",
      "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 13961\n",
      "})\n",
      "  val_tok  : Dataset({\n",
      "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 3262\n",
      "})\n",
      "  test_tok : Dataset({\n",
      "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 2544\n",
      "})\n",
      "\n",
      "Example tokenized item keys: dict_keys(['labels', 'input_ids', 'token_type_ids', 'attention_mask'])\n",
      "input_ids length: 64\n",
      "label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Build Hugging Face Datasets from the pandas splits and tokenize them\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "# Create base datasets with 'text' and 'label' columns\n",
    "train_ds = Dataset.from_pandas(\n",
    "    df_train[[\"product_text_norm\", \"label\"]].rename(columns={\"product_text_norm\": \"text\"})\n",
    ")\n",
    "val_ds = Dataset.from_pandas(\n",
    "    df_val[[\"product_text_norm\", \"label\"]].rename(columns={\"product_text_norm\": \"text\"})\n",
    ")\n",
    "test_ds = Dataset.from_pandas(\n",
    "    df_test[[\"product_text_norm\", \"label\"]].rename(columns={\"product_text_norm\": \"text\"})\n",
    ")\n",
    "\n",
    "print(\"Raw HF datasets:\")\n",
    "print(\"  train:\", train_ds)\n",
    "print(\"  val  :\", val_ds)\n",
    "print(\"  test :\", test_ds)\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "    )\n",
    "\n",
    "# Apply tokenizer\n",
    "train_ds_tok = train_ds.map(tokenize_batch, batched=True, remove_columns=[\"text\", \"__index_level_0__\"])\n",
    "val_ds_tok   = val_ds.map(tokenize_batch, batched=True, remove_columns=[\"text\", \"__index_level_0__\"])\n",
    "test_ds_tok  = test_ds.map(tokenize_batch, batched=True, remove_columns=[\"text\", \"__index_level_0__\"])\n",
    "\n",
    "# Set the format so Trainer gets tensors and labels\n",
    "train_ds_tok = train_ds_tok.rename_column(\"label\", \"labels\")\n",
    "val_ds_tok   = val_ds_tok.rename_column(\"label\", \"labels\")\n",
    "test_ds_tok  = test_ds_tok.rename_column(\"label\", \"labels\")\n",
    "\n",
    "print(\"\\nTokenized HF datasets:\")\n",
    "print(\"  train_tok:\", train_ds_tok)\n",
    "print(\"  val_tok  :\", val_ds_tok)\n",
    "print(\"  test_tok :\", test_ds_tok)\n",
    "\n",
    "# Inspect one tokenized example\n",
    "first_example = train_ds_tok[0]\n",
    "print(\"\\nExample tokenized item keys:\", first_example.keys())\n",
    "print(\"input_ids length:\", len(first_example[\"input_ids\"]))\n",
    "print(\"label:\", first_example[\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faa06b5",
   "metadata": {},
   "source": [
    "#### BERT sequence classification setup\n",
    "\n",
    "We now:\n",
    "- load `bert-base-uncased` as a sequence classification model with 2 labels,\n",
    "- define evaluation metrics (accuracy, precision, recall, F1 for \"fashion\" = label 1),\n",
    "- configure Hugging Face `Trainer` to fine-tune BERT on the train split and evaluate on the val split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b7129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer set up. Ready to fine-tune BERT.\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "\n",
    "# 1) Load BERT classifier (2 labels)\n",
    "id2label = {0: \"non-fashion\", 1: \"fashion\"}\n",
    "label2id = {\"non-fashion\": 0, \"fashion\": 1}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "# 2) Metrics: treat label 1 (\"fashion\") as the positive class\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"binary\", pos_label=1\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "# 3) Data collator (handles padding; we already use fixed length, so this is simple)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# 4) Training arguments\n",
    "bert_output_dir = project_root / \"models\" / \"bert_fashion\"\n",
    "os.makedirs(bert_output_dir, exist_ok=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(bert_output_dir),\n",
    "    evaluation_strategy=\"epoch\",      # run eval at end of each epoch\n",
    "    save_strategy=\"epoch\",            # save checkpoint each epoch\n",
    "    learning_rate=2e-5,               # standard BERT fine-tuning LR\n",
    "    per_device_train_batch_size=16,   # adjust if you hit memory issues\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,               # start with 2â€“3 epochs\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_f1\",\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=2,               # keep last 2 checkpoints\n",
    "    report_to=\"none\",                 # no wandb/tensorboard by default\n",
    ")\n",
    "\n",
    "# 5) Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds_tok,\n",
    "    eval_dataset=val_ds_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Trainer set up. Ready to fine-tune BERT.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37f653d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2619 [00:00<?, ?it/s]/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune BERT on the training set, evaluating on the validation set\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "# Save final model and training state\n",
    "trainer.save_model(bert_output_dir)        # saves the best model (because load_best_model_at_end=True)\n",
    "trainer.save_state()\n",
    "\n",
    "print(\"\\nTraining finished.\")\n",
    "print(\"Best model saved in:\", bert_output_dir)\n",
    "\n",
    "# Evaluate on validation and test splits\n",
    "print(\"\\n=== Evaluation on validation split ===\")\n",
    "eval_val = trainer.evaluate(eval_dataset=val_ds_tok)\n",
    "print(eval_val)\n",
    "\n",
    "print(\"\\n=== Evaluation on test split ===\")\n",
    "eval_test = trainer.evaluate(eval_dataset=test_ds_tok)\n",
    "print(eval_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashion-bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
