{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db8b6c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_root: /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation\n",
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Simple, self-contained BERT fine-tune using Hugging Face Trainer.\n",
    "\n",
    "from pathlib import Path\n",
    "import os, math, numpy as np, pandas as pd, polars as pl\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    Trainer, TrainingArguments, set_seed\n",
    ")\n",
    "from transformers.trainer import TrainerCallback\n",
    "\n",
    "# project folders\n",
    "candidates = [Path.cwd(), *Path.cwd().parents]\n",
    "project_root = next((p for p in candidates if (p / \"src\").exists() and (p / \"data\").exists()), None)\n",
    "if project_root is None:\n",
    "    raise RuntimeError(f\"could not find project root from {Path.cwd()}\")\n",
    "\n",
    "DATA = project_root / \"data\"\n",
    "INTERIM = DATA / \"interim\"\n",
    "PROCESSED = DATA / \"processed\"\n",
    "PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"project_root:\", project_root)\n",
    "print(\"device:\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# reproducibility\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a7c2725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizes -> train: 27179  val: 6851  test: 763\n",
      "class weights [neg, pos]: [3.1728928089141846, 0.593531608581543]\n"
     ]
    }
   ],
   "source": [
    "# Read leakage-safe splits\n",
    "spl = pl.read_parquet(INTERIM / \"splits_no_leak.parquet\")  # product_text, label, split\n",
    "assert {\"product_text\",\"label\",\"split\"} <= set(spl.columns), spl.columns\n",
    "\n",
    "# Convert to Pandas for Trainer\n",
    "def to_xy(df_pl):\n",
    "    pdf = df_pl.to_pandas()\n",
    "    return pdf[\"product_text\"].astype(str).tolist(), pdf[\"label\"].astype(int).tolist()\n",
    "\n",
    "X_tr, y_tr = to_xy(spl.filter(pl.col(\"split\")==\"train\").select(\"product_text\",\"label\"))\n",
    "X_val, y_val = to_xy(spl.filter(pl.col(\"split\")==\"val\").select(\"product_text\",\"label\"))\n",
    "X_te,  y_te  = to_xy(spl.filter(pl.col(\"split\")==\"test\").select(\"product_text\",\"label\"))\n",
    "\n",
    "print(\"sizes -> train:\", len(y_tr), \" val:\", len(y_val), \" test:\", len(y_te))\n",
    "\n",
    "# Class weights from train split (inverse frequency)\n",
    "neg = (np.array(y_tr)==0).sum()\n",
    "pos = (np.array(y_tr)==1).sum()\n",
    "w_neg = len(y_tr)/(2*neg)\n",
    "w_pos = len(y_tr)/(2*pos)\n",
    "class_weights = torch.tensor([w_neg, w_pos], dtype=torch.float)\n",
    "print(\"class weights [neg, pos]:\", class_weights.tolist())\n",
    "\n",
    "# Tokenizer\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "MAX_LEN = 64  # from your preflight check\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Build tokenized datasets\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "train_enc = tokenize_texts(X_tr)\n",
    "val_enc   = tokenize_texts(X_val)\n",
    "test_enc  = tokenize_texts(X_te)\n",
    "\n",
    "class SimpleDS(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: v[idx] for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "train_ds = SimpleDS(train_enc, y_tr)\n",
    "val_ds   = SimpleDS(val_enc, y_val)\n",
    "test_ds  = SimpleDS(test_enc, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d235b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "  0%|          | 0/2550 [00:00<?, ?it/s]le TOKENIZERS_PARALLELISM=(true | false)\n",
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "  4%|â–         | 100/2550 [00:35<12:53,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4967, 'grad_norm': 2.9535019397735596, 'learning_rate': 1.3071895424836602e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 200/2550 [01:06<12:17,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2236, 'grad_norm': 2.592268228530884, 'learning_rate': 1.9607843137254903e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 300/2550 [01:38<11:46,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1834, 'grad_norm': 4.504507541656494, 'learning_rate': 1.8773466833541928e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 400/2550 [02:10<11:21,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1726, 'grad_norm': 0.18419504165649414, 'learning_rate': 1.7939090529828956e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–‰        | 500/2550 [02:41<10:51,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.115, 'grad_norm': 5.962426662445068, 'learning_rate': 1.7104714226115978e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–Ž       | 600/2550 [03:13<10:17,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.116, 'grad_norm': 2.0833609104156494, 'learning_rate': 1.6270337922403006e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 700/2550 [03:45<09:45,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0758, 'grad_norm': 0.424828439950943, 'learning_rate': 1.5435961618690028e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆâ–      | 800/2550 [04:16<09:09,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0759, 'grad_norm': 0.0493951290845871, 'learning_rate': 1.4601585314977057e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 850/2550 [04:51<12:41,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08410386741161346, 'eval_accuracy': 0.9854035907166837, 'eval_macro_f1': 0.9715694997294309, 'eval_precision_pos': 0.9937941734183762, 'eval_recall_pos': 0.9890204151655515, 'eval_runtime': 18.8372, 'eval_samples_per_second': 363.695, 'eval_steps_per_second': 5.733, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 900/2550 [05:08<08:38,  3.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.053, 'grad_norm': 1.04912269115448, 'learning_rate': 1.3767209011264082e-05, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1000/2550 [05:40<08:06,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0733, 'grad_norm': 0.031436488032341, 'learning_rate': 1.2932832707551107e-05, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1100/2550 [06:11<07:34,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0525, 'grad_norm': 0.07025343924760818, 'learning_rate': 1.2098456403838132e-05, 'epoch': 1.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1200/2550 [06:43<07:03,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0619, 'grad_norm': 13.752769470214844, 'learning_rate': 1.1264080100125157e-05, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1300/2550 [07:14<06:31,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0395, 'grad_norm': 0.023846335709095, 'learning_rate': 1.0429703796412182e-05, 'epoch': 1.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1400/2550 [07:45<06:01,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0408, 'grad_norm': 1.064024567604065, 'learning_rate': 9.595327492699208e-06, 'epoch': 1.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1500/2550 [08:17<05:29,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0465, 'grad_norm': 0.18656472861766815, 'learning_rate': 8.760951188986233e-06, 'epoch': 1.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1600/2550 [08:48<04:58,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0394, 'grad_norm': 0.018608929589390755, 'learning_rate': 7.92657488527326e-06, 'epoch': 1.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1700/2550 [09:19<03:45,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0717, 'grad_norm': 0.11701826006174088, 'learning_rate': 7.092198581560285e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1700/2550 [09:38<03:45,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07317228615283966, 'eval_accuracy': 0.9916800467085097, 'eval_macro_f1': 0.9835121400195748, 'eval_precision_pos': 0.9938398357289527, 'eval_recall_pos': 0.9963973237261966, 'eval_runtime': 18.349, 'eval_samples_per_second': 373.372, 'eval_steps_per_second': 5.886, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1800/2550 [10:11<03:55,  3.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0175, 'grad_norm': 16.50838279724121, 'learning_rate': 6.25782227784731e-06, 'epoch': 2.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1900/2550 [10:42<03:24,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.014, 'grad_norm': 0.09427756816148758, 'learning_rate': 5.423445974134335e-06, 'epoch': 2.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2000/2550 [11:13<02:52,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0093, 'grad_norm': 0.19087456166744232, 'learning_rate': 4.589069670421361e-06, 'epoch': 2.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2100/2550 [11:45<02:21,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0147, 'grad_norm': 0.0435887947678566, 'learning_rate': 3.7546933667083856e-06, 'epoch': 2.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2200/2550 [12:16<01:49,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0132, 'grad_norm': 0.011025002226233482, 'learning_rate': 2.9203170629954116e-06, 'epoch': 2.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2300/2550 [12:47<01:18,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.028, 'grad_norm': 1.917508602142334, 'learning_rate': 2.0859407592824367e-06, 'epoch': 2.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2400/2550 [13:19<00:46,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0268, 'grad_norm': 0.0662963017821312, 'learning_rate': 1.251564455569462e-06, 'epoch': 2.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2500/2550 [13:50<00:15,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0292, 'grad_norm': 0.06501242518424988, 'learning_rate': 4.1718815185648727e-07, 'epoch': 2.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2550/2550 [14:06<00:00,  3.78it/s]/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                   \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2550/2550 [14:25<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.08361237496137619, 'eval_accuracy': 0.9918260108013429, 'eval_macro_f1': 0.9838865807745745, 'eval_precision_pos': 0.9950265820613959, 'eval_recall_pos': 0.9953679876479671, 'eval_runtime': 18.4362, 'eval_samples_per_second': 371.606, 'eval_steps_per_second': 5.858, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2550/2550 [14:27<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 867.3546, 'train_samples_per_second': 94.007, 'train_steps_per_second': 2.94, 'train_loss': 0.08208271726673724, 'epoch': 3.0}\n",
      "best model path: /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation/data/processed/bert_base_uncased_finetuned/checkpoint-2550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "\n",
    "# Weighted loss (handles class imbalance)\n",
    "# We override Trainer.compute_loss to apply CrossEntropy with weights.\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, class_weights=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.class_weights = class_weights.to(self.model.device) if class_weights is not None else None\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        if self.class_weights is None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        loss = loss_fct(logits.view(-1, model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    acc  = accuracy_score(labels, preds)\n",
    "    f1m  = f1_score(labels, preds, average=\"macro\")\n",
    "    prec = precision_score(labels, preds, pos_label=1, zero_division=0)\n",
    "    rec  = recall_score(labels, preds,    pos_label=1, zero_division=0)\n",
    "    return {\"accuracy\": acc, \"macro_f1\": f1m, \"precision_pos\": prec, \"recall_pos\": rec}\n",
    "\n",
    "output_dir = PROCESSED / \"bert_base_uncased_finetuned\"\n",
    "args = TrainingArguments(\n",
    "    output_dir=str(output_dir),\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.06,\n",
    "    logging_steps=100,\n",
    "    report_to=[],  # no wandb\n",
    ")\n",
    "\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    class_weights=class_weights,\n",
    ")\n",
    "\n",
    "train_out = trainer.train()\n",
    "print(\"best model path:\", trainer.state.best_model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed40a9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 108/108 [00:18<00:00,  5.92it/s]\n",
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL: {'eval_loss': 0.0836, 'eval_accuracy': 0.9918, 'eval_macro_f1': 0.9839, 'eval_precision_pos': 0.995, 'eval_recall_pos': 0.9954, 'eval_runtime': 18.856, 'eval_samples_per_second': 363.333, 'eval_steps_per_second': 5.728, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: {'test_loss': 0.0003, 'test_accuracy': 1.0, 'test_macro_f1': 1.0, 'test_precision_pos': 1.0, 'test_recall_pos': 1.0, 'test_runtime': 2.074, 'test_samples_per_second': 367.886, 'test_steps_per_second': 5.786}\n",
      "\n",
      "Confusion matrix [ [TN FP] [FN TP] ]:\n",
      " [[ 94   0]\n",
      " [  0 669]]\n",
      "\n",
      "Classification report (test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000        94\n",
      "           1      1.000     1.000     1.000       669\n",
      "\n",
      "    accuracy                          1.000       763\n",
      "   macro avg      1.000     1.000     1.000       763\n",
      "weighted avg      1.000     1.000     1.000       763\n",
      "\n",
      "wrote: /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation/data/processed/bert_test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation and test\n",
    "val_metrics = trainer.evaluate(val_ds)\n",
    "print(\"VAL:\", {k: round(v,4) for k,v in val_metrics.items() if isinstance(v,(float,int))})\n",
    "\n",
    "test_outputs = trainer.predict(test_ds)\n",
    "test_metrics = {k: (round(v,4) if isinstance(v,(float,int)) else v) for k,v in test_outputs.metrics.items()}\n",
    "print(\"TEST:\", test_metrics)\n",
    "\n",
    "# Confusion matrix on test\n",
    "test_pred = test_outputs.predictions.argmax(axis=-1)\n",
    "cm = confusion_matrix(y_te, test_pred)\n",
    "print(\"\\nConfusion matrix [ [TN FP] [FN TP] ]:\\n\", cm)\n",
    "print(\"\\nClassification report (test):\\n\", classification_report(y_te, test_pred, digits=3))\n",
    "\n",
    "# Save test predictions for manual review\n",
    "test_csv = PROCESSED / \"bert_test_predictions.csv\"\n",
    "pd.DataFrame({\n",
    "    \"product_text\": X_te,\n",
    "    \"true_label\": y_te,\n",
    "    \"pred_label\": test_pred,\n",
    "    \"prob_fashion\": torch.softmax(torch.tensor(test_outputs.predictions), dim=1)[:,1].numpy()\n",
    "}).to_csv(test_csv, index=False)\n",
    "print(\"wrote:\", test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d976709e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ramana/anaconda3/envs/fashion-bert/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1216/1216 [03:30<00:00,  5.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote: /Users/ramana/Documents/Homework/1st class ML opt/Project 1/Product-Classifcation/data/processed/bert_preds_202502.csv | rows: 77786\n"
     ]
    }
   ],
   "source": [
    "# Optional: score the latest monthâ€™s unlabeled names\n",
    "events_all = pl.read_parquet(INTERIM / \"events_all.parquet\")          # all cleaned names\n",
    "labeled_all = pl.read_parquet(INTERIM / \"labeled_all_clean.parquet\")  # labeled set\n",
    "\n",
    "unlabeled = events_all.join(labeled_all.select(\"product_text\").unique(),\n",
    "                            on=\"product_text\", how=\"anti\").unique()\n",
    "\n",
    "# pick latest month (max yyyymm)\n",
    "latest = unlabeled.select(\"yyyymm\").max().item()\n",
    "ul_latest = unlabeled.filter(pl.col(\"yyyymm\")==latest)\n",
    "\n",
    "if ul_latest.height > 0:\n",
    "    ul_texts = ul_latest[\"product_text\"].to_list()\n",
    "    ul_enc = tokenizer(ul_texts, padding=\"max_length\", truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "    ul_ds = SimpleDS(ul_enc, [0]*len(ul_texts))  # dummy labels\n",
    "    ul_pred = trainer.predict(ul_ds)\n",
    "    probs = torch.softmax(torch.tensor(ul_pred.predictions), dim=1)[:,1].numpy()\n",
    "    preds = probs >= 0.5\n",
    "\n",
    "    out_csv = PROCESSED / f\"bert_preds_{latest}.csv\"\n",
    "    pd.DataFrame({\n",
    "        \"month\": latest, \"product_text\": ul_texts,\n",
    "        \"prob_fashion\": probs, \"pred_label\": preds.astype(int)\n",
    "    }).to_csv(out_csv, index=False)\n",
    "    print(\"wrote:\", out_csv, \"| rows:\", len(ul_texts))\n",
    "else:\n",
    "    print(\"no unlabeled rows found for latest month.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashion-bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
